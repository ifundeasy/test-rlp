package scylladb

import (
	"context"
	"encoding/csv"
	"io"
	"log"
	"os"
	"path/filepath"
	"runtime"
	"sort"
	"strconv"
	"sync"
	"sync/atomic"
	"time"

	"github.com/gocql/gocql"

	"test-tls/infrastructure"
)

const (
	dataDir = "data"
)

const (
	insertBatchSize = 1000
)

// small int-set helper
type intSet map[int]struct{}

func (s intSet) add(v int) {
	s[v] = struct{}{}
}

func (s intSet) has(v int) bool {
	_, ok := s[v]
	return ok
}

// ScylladbCreateData loads the deterministic relational ACL dataset generated by
// cmd/csv/load_data.go into ScyllaDB, and additionally builds fully
// denormalized permission tables optimized for RLS check and list:
//
//   - user_resource_perms_by_user
//   - user_resource_perms_by_resource
//
// CSV files (supports nested groups via group_hierarchy.csv):
//
//	organizations.csv:      org_id
//	users.csv:              user_id,org_id
//	groups.csv:             group_id,org_id
//	org_memberships.csv:    org_id,user_id,role        // role in {member,admin}
//	group_memberships.csv:  group_id,user_id,role      // role in {direct_member,direct_manager}
//	group_hierarchy.csv:    parent_group_id,child_group_id,relation  // relation in {member_group,manager_group}
//	resources.csv:          resource_id,org_id
//	resource_acl.csv:       resource_id,subject_type,subject_id,relation
//	                        // relation: manager_user/viewer_user for users, manager_group/viewer_group for groups
//
// Permission semantics compiled with nested group expansion:
//
//	can_manage(user, resource) =
//	  direct manager_user
//	  OR via manager_group (recursively expands effective managers)
//	  OR via org admin
//
//	can_view(user, resource) =
//	  can_manage
//	  OR direct viewer_user
//	  OR via viewer_group (recursively expands effective members)
//	  OR via org member
func ScylladbCreateData() {
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Minute)
	defer cancel()

	session, cleanup, err := infrastructure.NewScyllaFromEnv(ctx)
	if err != nil {
		log.Fatalf("[scylladb] NewScyllaFromEnv failed: %v", err)
	}
	defer cleanup()

	start := time.Now()
	log.Printf("[scylladb] == Loading CSV data into ScyllaDB ==")

	clearTables(session)

	loadOrganizations(ctx, session)
	loadUsers(ctx, session)
	loadGroups(ctx, session)

	orgAdmins, orgMembers := loadOrgMemberships(ctx, session)
	groupMembers := loadGroupMemberships(ctx, session)
	groupHierarchy := loadGroupHierarchy(ctx, session)
	resourceOrg := loadResources(ctx, session)
	directUserManagers, directUserViewers, groupManagers, groupViewers := loadResourceACL(ctx, session)

	// Precompute group membership expansion for fast lookups
	buildGroupMembersExpanded(ctx, session, groupMembers, groupHierarchy)

	buildUserResourcePerms(
		ctx,
		session,
		resourceOrg,
		orgAdmins,
		orgMembers,
		groupMembers,
		groupHierarchy,
		directUserManagers,
		directUserViewers,
		groupManagers,
		groupViewers,
	)

	elapsed := time.Since(start).Truncate(time.Millisecond)
	log.Printf("[scylladb] ScyllaDB data load DONE: elapsed=%s", elapsed)
}

// =========================
// Table clearing
// =========================

func clearTables(session *gocql.Session) {
	tables := []string{
		"organizations",
		"users",
		"groups",
		"org_memberships",
		"group_memberships",
		"group_hierarchy",
		"group_members_expanded",
		"resources",
		"resource_acl_by_resource",
		"resource_acl_by_subject",
		"user_resource_perms_by_user",
		"user_resource_perms_by_resource",
	}

	for _, tbl := range tables {
		if err := session.Query("TRUNCATE " + tbl).Exec(); err != nil {
			log.Fatalf("[scylladb] TRUNCATE %s failed: %v", tbl, err)
		}
		log.Printf("[scylladb] Truncated %s", tbl)
	}
}

// =========================
// CSV helpers
// =========================

func openCSV(name string) (*csv.Reader, *os.File) {
	full := filepath.Join(dataDir, name)
	f, err := os.Open(full)
	if err != nil {
		log.Fatalf("[scylladb] open %s: %v", full, err)
	}
	r := csv.NewReader(f)
	return r, f
}

func mustAtoi(s, field string) int {
	v, err := strconv.Atoi(s)
	if err != nil {
		log.Fatalf("[scylladb] parse int for %s %q failed: %v", field, s, err)
	}
	return v
}

// execBatch executes the provided batch (if not empty) and returns a fresh batch.
func execBatch(session *gocql.Session, b *gocql.Batch, name string) *gocql.Batch {
	if b == nil || len(b.Entries) == 0 {
		return session.NewBatch(gocql.UnloggedBatch)
	}
	if err := session.ExecuteBatch(b); err != nil {
		log.Fatalf("[scylladb] ExecuteBatch %s failed: %v", name, err)
	}
	return session.NewBatch(gocql.UnloggedBatch)
}

// =========================
// Load organizations
// =========================

func loadOrganizations(ctx context.Context, session *gocql.Session) {
	r, f := openCSV("organizations.csv")
	defer f.Close()

	// header: org_id
	if _, err := r.Read(); err != nil {
		log.Fatalf("[scylladb] read organizations header: %v", err)
	}

	count := 0
	batch := session.NewBatch(gocql.UnloggedBatch)
	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[scylladb] organizations: read row failed: %v", err)
		}
		if len(rec) < 1 {
			log.Fatalf("[scylladb] organizations: invalid row: %#v", rec)
		}

		orgID := mustAtoi(rec[0], "organizations.org_id")

		batch.Query("INSERT INTO organizations (org_id) VALUES (?)", orgID)
		count++

		if len(batch.Entries) >= insertBatchSize {
			batch = execBatch(session, batch, "organizations")
		}
	}

	if len(batch.Entries) > 0 {
		_ = execBatch(session, batch, "organizations")
	}
	log.Printf("[scylladb] organizations: inserted %d rows", count)
}

// =========================
// Load users
// =========================

func loadUsers(ctx context.Context, session *gocql.Session) {
	r, f := openCSV("users.csv")
	defer f.Close()

	// header: user_id,org_id
	if _, err := r.Read(); err != nil {
		log.Fatalf("[scylladb] read users header: %v", err)
	}

	count := 0
	batch := session.NewBatch(gocql.UnloggedBatch)
	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[scylladb] users: read row failed: %v", err)
		}
		if len(rec) < 2 {
			log.Fatalf("[scylladb] users: invalid row: %#v", rec)
		}

		userID := mustAtoi(rec[0], "users.user_id")
		orgID := mustAtoi(rec[1], "users.org_id")

		batch.Query("INSERT INTO users (user_id, org_id) VALUES (?, ?)", userID, orgID)
		count++

		if len(batch.Entries) >= insertBatchSize {
			batch = execBatch(session, batch, "users")
		}
	}

	if len(batch.Entries) > 0 {
		_ = execBatch(session, batch, "users")
	}
	log.Printf("[scylladb] users: inserted %d rows", count)
}

// =========================
// Load groups
// =========================

func loadGroups(ctx context.Context, session *gocql.Session) {
	r, f := openCSV("groups.csv")
	defer f.Close()

	// header: group_id,org_id
	if _, err := r.Read(); err != nil {
		log.Fatalf("[scylladb] read groups header: %v", err)
	}

	count := 0
	batch := session.NewBatch(gocql.UnloggedBatch)
	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[scylladb] groups: read row failed: %v", err)
		}
		if len(rec) < 2 {
			log.Fatalf("[scylladb] groups: invalid row: %#v", rec)
		}

		groupID := mustAtoi(rec[0], "groups.group_id")
		orgID := mustAtoi(rec[1], "groups.org_id")

		batch.Query("INSERT INTO groups (group_id, org_id) VALUES (?, ?)", groupID, orgID)
		count++

		if len(batch.Entries) >= insertBatchSize {
			batch = execBatch(session, batch, "groups")
		}
	}

	if len(batch.Entries) > 0 {
		_ = execBatch(session, batch, "groups")
	}
	log.Printf("[scylladb] groups: inserted %d rows", count)
}

// =========================
// Load org_memberships
// =========================
//
// org_memberships.csv: org_id,user_id,role
//
// Also builds maps:
//
//	orgAdmins[orgID]  -> set of userID
//	orgMembers[orgID] -> set of userID
func loadOrgMemberships(ctx context.Context, session *gocql.Session) (map[int]intSet, map[int]intSet) {
	r, f := openCSV("org_memberships.csv")
	defer f.Close()

	// header: org_id,user_id,role
	if _, err := r.Read(); err != nil {
		log.Fatalf("[scylladb] read org_memberships header: %v", err)
	}

	orgAdmins := make(map[int]intSet)
	orgMembers := make(map[int]intSet)

	count := 0
	batch := session.NewBatch(gocql.UnloggedBatch)
	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[scylladb] org_memberships: read row failed: %v", err)
		}
		if len(rec) < 3 {
			log.Fatalf("[scylladb] org_memberships: invalid row: %#v", rec)
		}

		orgID := mustAtoi(rec[0], "org_memberships.org_id")
		userID := mustAtoi(rec[1], "org_memberships.user_id")
		role := rec[2]

		batch.Query("INSERT INTO org_memberships (org_id, user_id, role) VALUES (?, ?, ?)", orgID, userID, role)
		count++
		if len(batch.Entries) >= insertBatchSize {
			batch = execBatch(session, batch, "org_memberships")
		}

		switch role {
		case "admin":
			s, ok := orgAdmins[orgID]
			if !ok {
				s = make(intSet)
				orgAdmins[orgID] = s
			}
			s.add(userID)
		case "member":
			s, ok := orgMembers[orgID]
			if !ok {
				s = make(intSet)
				orgMembers[orgID] = s
			}
			s.add(userID)
		default:
			log.Fatalf("[scylladb] org_memberships: unknown role %q", role)
		}
	}
	if len(batch.Entries) > 0 {
		_ = execBatch(session, batch, "org_memberships")
	}
	log.Printf("[scylladb] org_memberships: inserted %d rows", count)
	return orgAdmins, orgMembers
}

// =========================
// Load group_memberships
// =========================
//
// group_memberships.csv: group_id,user_id,role
//
// Builds:
//
//	groupMembers[groupID] -> set of userID
func loadGroupMemberships(ctx context.Context, session *gocql.Session) map[int]intSet {
	r, f := openCSV("group_memberships.csv")
	defer f.Close()

	// header: group_id,user_id,role
	if _, err := r.Read(); err != nil {
		log.Fatalf("[scylladb] read group_memberships header: %v", err)
	}

	groupMembers := make(map[int]intSet)

	count := 0
	batch := session.NewBatch(gocql.UnloggedBatch)
	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[scylladb] group_memberships: read row failed: %v", err)
		}
		if len(rec) < 3 {
			log.Fatalf("[scylladb] group_memberships: invalid row: %#v", rec)
		}

		groupID := mustAtoi(rec[0], "group_memberships.group_id")
		userID := mustAtoi(rec[1], "group_memberships.user_id")
		role := rec[2]

		batch.Query("INSERT INTO group_memberships (user_id, group_id, role) VALUES (?, ?, ?)", userID, groupID, role)
		count++
		if len(batch.Entries) >= insertBatchSize {
			batch = execBatch(session, batch, "group_memberships")
		}

		// role is currently always "member"
		s, ok := groupMembers[groupID]
		if !ok {
			s = make(intSet)
			groupMembers[groupID] = s
		}
		s.add(userID)
	}

	if len(batch.Entries) > 0 {
		_ = execBatch(session, batch, "group_memberships")
	}

	log.Printf("[scylladb] group_memberships: inserted %d rows", count)
	return groupMembers
}

// =========================
// Load group_hierarchy
// =========================
//
// group_hierarchy.csv: parent_group_id,child_group_id,relation
//
// Builds:
//
//	groupHierarchy[parentID] -> map of (childID, relation)
func loadGroupHierarchy(ctx context.Context, session *gocql.Session) map[int]map[int]string {
	full := filepath.Join(dataDir, "group_hierarchy.csv")
	f, err := os.Open(full)
	if err != nil {
		if os.IsNotExist(err) {
			log.Printf("[scylladb] group_hierarchy.csv not found, skipping nested groups")
			return make(map[int]map[int]string)
		}
		log.Fatalf("[scylladb] open group_hierarchy.csv: %v", err)
	}
	defer f.Close()
	r := csv.NewReader(f)

	// header: parent_group_id,child_group_id,relation
	if _, err := r.Read(); err != nil {
		log.Fatalf("[scylladb] read group_hierarchy header: %v", err)
	}

	groupHierarchy := make(map[int]map[int]string)
	count := 0
	batch := session.NewBatch(gocql.UnloggedBatch)

	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[scylladb] group_hierarchy: read row failed: %v", err)
		}
		if len(rec) < 3 {
			log.Fatalf("[scylladb] group_hierarchy: invalid row: %#v", rec)
		}

		parentID := mustAtoi(rec[0], "group_hierarchy.parent_group_id")
		childID := mustAtoi(rec[1], "group_hierarchy.child_group_id")
		relation := rec[2]

		batch.Query(
			"INSERT INTO group_hierarchy (parent_group_id, child_group_id, relation) VALUES (?, ?, ?)",
			parentID, childID, relation,
		)
		count++

		if len(batch.Entries) >= insertBatchSize {
			batch = execBatch(session, batch, "group_hierarchy")
		}

		// Build in-memory hierarchy map
		if _, ok := groupHierarchy[parentID]; !ok {
			groupHierarchy[parentID] = make(map[int]string)
		}
		groupHierarchy[parentID][childID] = relation
	}

	if len(batch.Entries) > 0 {
		_ = execBatch(session, batch, "group_hierarchy")
	}

	log.Printf("[scylladb] group_hierarchy: inserted %d rows", count)
	return groupHierarchy
}

// =========================
// Build group_members_expanded
// =========================
//
// Precomputes all transitive group members/managers for O(1) lookups.
// This eliminates expensive recursive expansion during permission queries.
func buildGroupMembersExpanded(
	ctx context.Context,
	session *gocql.Session,
	groupMembers map[int]intSet,
	groupHierarchy map[int]map[int]string,
) {
	start := time.Now()
	totalRows := 0

	log.Printf("[scylladb] Precomputing group_members_expanded (transitive closure) ...")

	// Memoization for recursive expansion
	mgrMemo := make(map[int]map[int]bool)
	memMemo := make(map[int]map[int]bool)

	// Recursive expansion for managers
	var computeEffectiveManagersForGroup func(int) map[int]bool
	computeEffectiveManagersForGroup = func(groupID int) map[int]bool {
		if cached, ok := mgrMemo[groupID]; ok {
			return cached
		}

		effective := make(map[int]bool)

		// Direct managers
		if members, ok := groupMembers[groupID]; ok {
			for u := range members {
				effective[u] = true
			}
		}

		// Recursively add managers from child groups via manager_group edges
		if children, ok := groupHierarchy[groupID]; ok {
			for childID, rel := range children {
				if rel == "manager_group" {
					for u := range computeEffectiveManagersForGroup(childID) {
						effective[u] = true
					}
				}
			}
		}

		mgrMemo[groupID] = effective
		return effective
	}

	// Recursive expansion for members
	var computeEffectiveMembersForGroup func(int) map[int]bool
	computeEffectiveMembersForGroup = func(groupID int) map[int]bool {
		if cached, ok := memMemo[groupID]; ok {
			return cached
		}

		effective := make(map[int]bool)

		// Direct members
		if members, ok := groupMembers[groupID]; ok {
			for u := range members {
				effective[u] = true
			}
		}

		// Recursively add members from child groups via member_group edges
		if children, ok := groupHierarchy[groupID]; ok {
			for childID, rel := range children {
				if rel == "member_group" {
					for u := range computeEffectiveMembersForGroup(childID) {
						effective[u] = true
					}
				}
			}
		}

		// Include managers as members
		for u := range computeEffectiveManagersForGroup(groupID) {
			effective[u] = true
		}

		memMemo[groupID] = effective
		return effective
	}

	// Precompute for all groups (include groups that only appear in hierarchy)
	batch := session.NewBatch(gocql.UnloggedBatch)

	// Build the union of all group IDs from direct memberships and hierarchy
	allGroups := make(map[int]struct{})
	for g := range groupMembers {
		allGroups[g] = struct{}{}
	}
	for parent, children := range groupHierarchy {
		allGroups[parent] = struct{}{}
		for child := range children {
			allGroups[child] = struct{}{}
		}
	}

	for groupID := range allGroups {
		// Insert effective managers
		effectiveManagers := computeEffectiveManagersForGroup(groupID)
		for userID := range effectiveManagers {
			batch.Query(
				"INSERT INTO group_members_expanded (group_id, user_id, role) VALUES (?, ?, ?)",
				groupID, userID, "manager",
			)
			totalRows++

			if len(batch.Entries) >= insertBatchSize {
				batch = execBatch(session, batch, "group_members_expanded")
			}
		}

		// Insert effective members
		effectiveMembers := computeEffectiveMembersForGroup(groupID)
		for userID := range effectiveMembers {
			batch.Query(
				"INSERT INTO group_members_expanded (group_id, user_id, role) VALUES (?, ?, ?)",
				groupID, userID, "member",
			)
			totalRows++

			if len(batch.Entries) >= insertBatchSize {
				batch = execBatch(session, batch, "group_members_expanded")
			}
		}
	}

	if len(batch.Entries) > 0 {
		_ = execBatch(session, batch, "group_members_expanded")
	}

	elapsed := time.Since(start).Truncate(time.Millisecond)
	log.Printf("[scylladb] group_members_expanded: precomputed %d rows in %s", totalRows, elapsed)
}

// =========================
// Load resources
// =========================
//
// resources.csv: resource_id,org_id
//
// Builds:
//
//	resourceOrg[resourceID] -> orgID
func loadResources(ctx context.Context, session *gocql.Session) map[int]int {
	r, f := openCSV("resources.csv")
	defer f.Close()

	// header: resource_id,org_id
	if _, err := r.Read(); err != nil {
		log.Fatalf("[scylladb] read resources header: %v", err)
	}

	resourceOrg := make(map[int]int)
	count := 0
	batch := session.NewBatch(gocql.UnloggedBatch)

	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[scylladb] resources: read row failed: %v", err)
		}
		if len(rec) < 2 {
			log.Fatalf("[scylladb] resources: invalid row: %#v", rec)
		}

		resID := mustAtoi(rec[0], "resources.resource_id")
		orgID := mustAtoi(rec[1], "resources.org_id")

		batch.Query("INSERT INTO resources (resource_id, org_id) VALUES (?, ?)", resID, orgID)
		count++

		if len(batch.Entries) >= insertBatchSize {
			batch = execBatch(session, batch, "resources")
		}

		resourceOrg[resID] = orgID
	}

	if len(batch.Entries) > 0 {
		_ = execBatch(session, batch, "resources")
	}

	log.Printf("[scylladb] resources: inserted %d rows", count)
	return resourceOrg
}

// =========================
// Load resource_acl
// =========================
//
// resource_acl.csv: resource_id,subject_type,subject_id,relation
//
// Writes into:
//
//	resource_acl_by_resource
//	resource_acl_by_subject
//
// Builds:
//
//	directUserManagers[resID] -> set of userID
//	directUserViewers[resID]  -> set of userID
//	groupManagers[resID]      -> set of groupID
//	groupViewers[resID]       -> set of groupID
func loadResourceACL(
	ctx context.Context,
	session *gocql.Session,
) (map[int]intSet, map[int]intSet, map[int]intSet, map[int]intSet) {
	r, f := openCSV("resource_acl.csv")
	defer f.Close()

	// header: resource_id,subject_type,subject_id,relation
	if _, err := r.Read(); err != nil {
		log.Fatalf("[scylladb] read resource_acl header: %v", err)
	}

	directUserManagers := make(map[int]intSet)
	directUserViewers := make(map[int]intSet)
	groupManagers := make(map[int]intSet)
	groupViewers := make(map[int]intSet)

	count := 0
	batchByResource := session.NewBatch(gocql.UnloggedBatch)
	batchBySubject := session.NewBatch(gocql.UnloggedBatch)
	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[scylladb] resource_acl: read row failed: %v", err)
		}
		if len(rec) < 4 {
			log.Fatalf("[scylladb] resource_acl: invalid row: %#v", rec)
		}

		resID := mustAtoi(rec[0], "resource_acl.resource_id")
		subjectType := rec[1]
		subjectID := mustAtoi(rec[2], "resource_acl.subject_id")
		relation := rec[3]

		// Insert into resource_acl_by_resource (batched)
		batchByResource.Query(
			"INSERT INTO resource_acl_by_resource (resource_id, relation, subject_type, subject_id) VALUES (?, ?, ?, ?)",
			resID, relation, subjectType, subjectID,
		)
		// Insert into resource_acl_by_subject (batched)
		batchBySubject.Query(
			"INSERT INTO resource_acl_by_subject (subject_type, subject_id, relation, resource_id) VALUES (?, ?, ?, ?)",
			subjectType, subjectID, relation, resID,
		)

		count++

		if len(batchByResource.Entries) >= insertBatchSize {
			batchByResource = execBatch(session, batchByResource, "resource_acl_by_resource")
		}
		if len(batchBySubject.Entries) >= insertBatchSize {
			batchBySubject = execBatch(session, batchBySubject, "resource_acl_by_subject")
		}

		switch subjectType {
		case "user":
			switch relation {
			case "manager_user", "manager":
				s, ok := directUserManagers[resID]
				if !ok {
					s = make(intSet)
					directUserManagers[resID] = s
				}
				s.add(subjectID)
			case "viewer_user", "viewer":
				s, ok := directUserViewers[resID]
				if !ok {
					s = make(intSet)
					directUserViewers[resID] = s
				}
				s.add(subjectID)
			default:
				log.Fatalf("[scylladb] resource_acl: unknown relation for user: %q", relation)
			}

		case "group":
			switch relation {
			case "manager_group", "manager":
				s, ok := groupManagers[resID]
				if !ok {
					s = make(intSet)
					groupManagers[resID] = s
				}
				s.add(subjectID)
			case "viewer_group", "viewer":
				s, ok := groupViewers[resID]
				if !ok {
					s = make(intSet)
					groupViewers[resID] = s
				}
				s.add(subjectID)
			default:
				log.Fatalf("[scylladb] resource_acl: unknown relation for group: %q", relation)
			}

		default:
			log.Fatalf("[scylladb] resource_acl: unknown subject_type: %q", subjectType)
		}
	}

	if len(batchByResource.Entries) > 0 {
		_ = execBatch(session, batchByResource, "resource_acl_by_resource")
	}
	if len(batchBySubject.Entries) > 0 {
		_ = execBatch(session, batchBySubject, "resource_acl_by_subject")
	}

	log.Printf("[scylladb] resource_acl: inserted %d rows", count)
	return directUserManagers, directUserViewers, groupManagers, groupViewers
}

// =========================
// Build user_resource_perms_*
// =========================

func buildUserResourcePerms(
	ctx context.Context,
	session *gocql.Session,
	resourceOrg map[int]int,
	orgAdmins map[int]intSet,
	orgMembers map[int]intSet,
	groupMembers map[int]intSet,
	groupHierarchy map[int]map[int]string,
	directUserManagers map[int]intSet,
	directUserViewers map[int]intSet,
	groupManagers map[int]intSet,
	groupViewers map[int]intSet,
) {
	start := time.Now()
	totalPerms := 0

	log.Printf("[scylladb] Building user_resource_perms_by_user & _by_resource ...")

	// Memoization for recursive expansion of precomputed groups
	mgrMemo := make(map[int]map[int]bool)
	memMemo := make(map[int]map[int]bool)

	var computeEffectiveManagersForGroup func(int) map[int]bool
	computeEffectiveManagersForGroup = func(groupID int) map[int]bool {
		if cached, ok := mgrMemo[groupID]; ok {
			return cached
		}

		effective := make(map[int]bool)

		// Direct managers
		if members, ok := groupMembers[groupID]; ok {
			for u := range members {
				effective[u] = true
			}
		}

		// Recursively add managers from child groups via manager_group edges
		if children, ok := groupHierarchy[groupID]; ok {
			for childID, rel := range children {
				if rel == "manager_group" {
					for u := range computeEffectiveManagersForGroup(childID) {
						effective[u] = true
					}
				}
			}
		}

		mgrMemo[groupID] = effective
		return effective
	}

	var computeEffectiveMembersForGroup func(int) map[int]bool
	computeEffectiveMembersForGroup = func(groupID int) map[int]bool {
		if cached, ok := memMemo[groupID]; ok {
			return cached
		}

		effective := make(map[int]bool)

		// Direct members
		if members, ok := groupMembers[groupID]; ok {
			for u := range members {
				effective[u] = true
			}
		}

		// Recursively add members from child groups via member_group edges
		if children, ok := groupHierarchy[groupID]; ok {
			for childID, rel := range children {
				if rel == "member_group" {
					for u := range computeEffectiveMembersForGroup(childID) {
						effective[u] = true
					}
				}
			}
		}

		// Include managers as members
		for u := range computeEffectiveManagersForGroup(groupID) {
			effective[u] = true
		}

		memMemo[groupID] = effective
		return effective
	}

	// Build a stable list of resource IDs so we can report progress.
	resourceIDs := make([]int, 0, len(resourceOrg))
	for id := range resourceOrg {
		resourceIDs = append(resourceIDs, id)
	}
	sort.Ints(resourceIDs)

	// Precompute effective managers/members for all groups referenced
	allGroups := make(map[int]struct{})
	for g := range groupMembers {
		allGroups[g] = struct{}{}
	}
	for parent, children := range groupHierarchy {
		allGroups[parent] = struct{}{}
		for child := range children {
			allGroups[child] = struct{}{}
		}
	}

	grpCount := 0
	for g := range allGroups {
		// populate memo caches
		_ = computeEffectiveManagersForGroup(g)
		_ = computeEffectiveMembersForGroup(g)
		grpCount++
	}
	log.Printf("[scylladb] precomputed effective group memberships for %d groups", grpCount)

	// Use a worker pool to process resources in parallel. Each worker keeps
	// local batches to reduce contention on shared batches and flushes them
	// periodically. Progress is reported via an atomic counter.
	workers := runtime.NumCPU()
	if workers < 2 {
		workers = 2
	}

	jobs := make(chan int, workers*4)
	var wg sync.WaitGroup
	var processed uint64
	var flushedBatches uint64
	var totalPerms64 uint64

	// Worker function
	worker := func() {
		defer wg.Done()

		localBatchByUser := session.NewBatch(gocql.UnloggedBatch)
		localBatchByRes := session.NewBatch(gocql.UnloggedBatch)
		localFlushed := 0

		for resID := range jobs {
			orgID := resourceOrg[resID]

			manageUsers := make(intSet)
			viewUsers := make(intSet)

			// 1) direct manager users
			if s, ok := directUserManagers[resID]; ok {
				for u := range s {
					manageUsers.add(u)
				}
			}

			// 2) managers via manager_group relations
			if mgrGroups, ok := groupManagers[resID]; ok {
				for g := range mgrGroups {
					effectiveManagers := computeEffectiveManagersForGroup(g)
					for u := range effectiveManagers {
						manageUsers.add(u)
					}
				}
			}

			// 3) org admins
			if admins, ok := orgAdmins[orgID]; ok {
				for u := range admins {
					manageUsers.add(u)
				}
			}

			// 4) viewUsers starts as manageUsers
			for u := range manageUsers {
				viewUsers.add(u)
			}

			// 5) direct viewers
			if viewers, ok := directUserViewers[resID]; ok {
				for u := range viewers {
					viewUsers.add(u)
				}
			}

			// 6) viewers via viewer_group relations
			if viewerGroups, ok := groupViewers[resID]; ok {
				for g := range viewerGroups {
					effectiveMembers := computeEffectiveMembersForGroup(g)
					for u := range effectiveMembers {
						viewUsers.add(u)
					}
				}
			}

			// 7) org members
			if members, ok := orgMembers[orgID]; ok {
				for u := range members {
					viewUsers.add(u)
				}
			}

			if len(viewUsers) == 0 {
				atomic.AddUint64(&processed, 1)
				continue
			}

			// Accumulate into local batches
			for u := range viewUsers {
				canManage := manageUsers.has(u)
				canView := true

				localBatchByUser.Query(
					"INSERT INTO user_resource_perms_by_user (user_id, resource_id, can_manage, can_view) VALUES (?, ?, ?, ?)",
					u, resID, canManage, canView,
				)
				localBatchByRes.Query(
					"INSERT INTO user_resource_perms_by_resource (resource_id, user_id, can_manage, can_view) VALUES (?, ?, ?, ?)",
					resID, u, canManage, canView,
				)

				atomic.AddUint64(&totalPerms64, 1)

				if len(localBatchByUser.Entries) >= insertBatchSize {
					localBatchByUser = execBatch(session, localBatchByUser, "user_resource_perms_by_user")
					localFlushed++
					atomic.AddUint64(&flushedBatches, 1)
				}
				if len(localBatchByRes.Entries) >= insertBatchSize {
					localBatchByRes = execBatch(session, localBatchByRes, "user_resource_perms_by_resource")
					localFlushed++
					atomic.AddUint64(&flushedBatches, 1)
				}
			}

			atomic.AddUint64(&processed, 1)
		}

		// flush remaining local batches
		if localBatchByUser != nil && len(localBatchByUser.Entries) > 0 {
			_ = execBatch(session, localBatchByUser, "user_resource_perms_by_user")
			localFlushed++
			atomic.AddUint64(&flushedBatches, 1)
		}
		if localBatchByRes != nil && len(localBatchByRes.Entries) > 0 {
			_ = execBatch(session, localBatchByRes, "user_resource_perms_by_resource")
			localFlushed++
			atomic.AddUint64(&flushedBatches, 1)
		}
	}

	// start workers
	wg.Add(workers)
	for w := 0; w < workers; w++ {
		go worker()
	}

	// progress ticker
	ticker := time.NewTicker(2 * time.Second)
	done := make(chan struct{})
	go func() {
		defer ticker.Stop()
		for {
			select {
			case <-ticker.C:
				p := atomic.LoadUint64(&processed)
				tp := atomic.LoadUint64(&totalPerms64)
				fb := atomic.LoadUint64(&flushedBatches)
				elapsedSoFar := time.Since(start).Truncate(time.Millisecond)
				log.Printf("[scylladb] buildUserResourcePerms: processed=%d/%d perms=%d elapsed=%s flushedBatches=%d",
					p, len(resourceIDs), tp, elapsedSoFar, fb)
			case <-done:
				return
			}
		}
	}()

	// feed jobs
	for _, resID := range resourceIDs {
		jobs <- resID
	}
	close(jobs)
	wg.Wait()
	close(done)

	// set totals back to locals for logging
	flushedBatches = atomic.LoadUint64(&flushedBatches)
	totalPerms = int(atomic.LoadUint64(&totalPerms64))

	elapsed := time.Since(start).Truncate(time.Millisecond)
	log.Printf("[scylladb] Built user_resource_perms_*: %d user-resource rows in %s (batches_flushed=%d)", totalPerms, elapsed, flushedBatches)
}
