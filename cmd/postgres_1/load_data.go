// cmd/postgres_1/load_data.go
package postgres_1

import (
	"context"
	"database/sql"
	"encoding/csv"
	"io"
	"log"
	"os"
	"path/filepath"
	"time"

	pq "github.com/lib/pq"

	"test-tls/infrastructure"
)

const dataDir = "data"

// PostgresCreateData loads the deterministic relational ACL dataset generated by
// cmd/csv/load_data.go into PostgreSQL tables defined in schemas.sql.
//
// Tables and CSV files:
//
//	organizations.csv:     org_id
//	users.csv:             user_id,org_id
//	groups.csv:            group_id,org_id
//	org_memberships.csv:   org_id,user_id,role
//	group_memberships.csv: group_id,user_id,role
//	resources.csv:         resource_id,org_id
//	resource_acl.csv:      resource_id,subject_type,subject_id,relation
func PostgresCreateData() {
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Minute)
	defer cancel()

	db, cleanup, err := infrastructure.NewPostgresFromEnv(ctx)
	if err != nil {
		log.Fatalf("[postgres_1] load_data: connect failed: %v", err)
	}
	defer cleanup()

	startAll := time.Now()
	log.Printf("[postgres_1] load_data: loading CSV data from %q ...", dataDir)

	loadOrganizations(db)
	loadUsers(db)
	loadGroups(db)
	loadOrgMemberships(db)
	loadGroupMemberships(db)
	loadResources(db)
	loadResourceACL(db)

	log.Printf("[postgres_1] load_data: ALL DONE in %s", time.Since(startAll).Truncate(time.Millisecond))
}

// =========================
// CSV helper
// =========================

func openCSV(name string) (*csv.Reader, *os.File) {
	full := filepath.Join(dataDir, name)
	f, err := os.Open(full)
	if err != nil {
		log.Fatalf("[postgres_1] load_data: open %s: %v", full, err)
	}
	r := csv.NewReader(f)
	return r, f
}

// =========================
// Load functions per table
// =========================

func loadOrganizations(db *sql.DB) {
	start := time.Now()
	r, f := openCSV("organizations.csv")
	defer f.Close()

	// organizations.csv: org_id
	if _, err := r.Read(); err != nil {
		log.Fatalf("[postgres_1] organizations: read header failed: %v", err)
	}

	tx, err := db.Begin()
	if err != nil {
		log.Fatalf("[postgres_1] organizations: begin tx failed: %v", err)
	}

	stmt, err := tx.Prepare(pq.CopyIn("organizations", "org_id"))
	if err != nil {
		log.Fatalf("[postgres_1] organizations: prepare CopyIn failed: %v", err)
	}

	count := 0
	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[postgres_1] organizations: read row failed: %v", err)
		}
		if len(rec) < 1 {
			log.Fatalf("[postgres_1] organizations: invalid row: %#v", rec)
		}

		if _, err := stmt.Exec(rec[0]); err != nil {
			log.Fatalf("[postgres_1] organizations: CopyIn exec failed: %v", err)
		}
		count++
	}

	if _, err := stmt.Exec(); err != nil {
		log.Fatalf("[postgres_1] organizations: final CopyIn exec failed: %v", err)
	}
	if err := stmt.Close(); err != nil {
		log.Fatalf("[postgres_1] organizations: close stmt failed: %v", err)
	}
	if err := tx.Commit(); err != nil {
		log.Fatalf("[postgres_1] organizations: commit failed: %v", err)
	}

	log.Printf("[postgres_1] organizations: inserted %d rows in %s",
		count, time.Since(start).Truncate(time.Millisecond))
}

func loadUsers(db *sql.DB) {
	start := time.Now()
	r, f := openCSV("users.csv")
	defer f.Close()

	// users.csv: user_id,org_id
	if _, err := r.Read(); err != nil {
		log.Fatalf("[postgres_1] users: read header failed: %v", err)
	}

	tx, err := db.Begin()
	if err != nil {
		log.Fatalf("[postgres_1] users: begin tx failed: %v", err)
	}

	stmt, err := tx.Prepare(pq.CopyIn("users", "user_id", "org_id"))
	if err != nil {
		log.Fatalf("[postgres_1] users: prepare CopyIn failed: %v", err)
	}

	count := 0
	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[postgres_1] users: read row failed: %v", err)
		}
		if len(rec) < 2 {
			log.Fatalf("[postgres_1] users: invalid row: %#v", rec)
		}

		if _, err := stmt.Exec(rec[0], rec[1]); err != nil {
			log.Fatalf("[postgres_1] users: CopyIn exec failed: %v", err)
		}
		count++
	}

	if _, err := stmt.Exec(); err != nil {
		log.Fatalf("[postgres_1] users: final CopyIn exec failed: %v", err)
	}
	if err := stmt.Close(); err != nil {
		log.Fatalf("[postgres_1] users: close stmt failed: %v", err)
	}
	if err := tx.Commit(); err != nil {
		log.Fatalf("[postgres_1] users: commit failed: %v", err)
	}

	log.Printf("[postgres_1] users: inserted %d rows in %s",
		count, time.Since(start).Truncate(time.Millisecond))
}

func loadGroups(db *sql.DB) {
	start := time.Now()
	r, f := openCSV("groups.csv")
	defer f.Close()

	// groups.csv: group_id,org_id
	if _, err := r.Read(); err != nil {
		log.Fatalf("[postgres_1] groups: read header failed: %v", err)
	}

	tx, err := db.Begin()
	if err != nil {
		log.Fatalf("[postgres_1] groups: begin tx failed: %v", err)
	}

	stmt, err := tx.Prepare(pq.CopyIn("groups", "group_id", "org_id"))
	if err != nil {
		log.Fatalf("[postgres_1] groups: prepare CopyIn failed: %v", err)
	}

	count := 0
	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[postgres_1] groups: read row failed: %v", err)
		}
		if len(rec) < 2 {
			log.Fatalf("[postgres_1] groups: invalid row: %#v", rec)
		}

		if _, err := stmt.Exec(rec[0], rec[1]); err != nil {
			log.Fatalf("[postgres_1] groups: CopyIn exec failed: %v", err)
		}
		count++
	}

	if _, err := stmt.Exec(); err != nil {
		log.Fatalf("[postgres_1] groups: final CopyIn exec failed: %v", err)
	}
	if err := stmt.Close(); err != nil {
		log.Fatalf("[postgres_1] groups: close stmt failed: %v", err)
	}
	if err := tx.Commit(); err != nil {
		log.Fatalf("[postgres_1] groups: commit failed: %v", err)
	}

	log.Printf("[postgres_1] groups: inserted %d rows in %s",
		count, time.Since(start).Truncate(time.Millisecond))
}

func loadOrgMemberships(db *sql.DB) {
	start := time.Now()
	r, f := openCSV("org_memberships.csv")
	defer f.Close()

	// org_memberships.csv: org_id,user_id,role
	if _, err := r.Read(); err != nil {
		log.Fatalf("[postgres_1] org_memberships: read header failed: %v", err)
	}

	tx, err := db.Begin()
	if err != nil {
		log.Fatalf("[postgres_1] org_memberships: begin tx failed: %v", err)
	}

	stmt, err := tx.Prepare(pq.CopyIn("org_memberships", "org_id", "user_id", "role"))
	if err != nil {
		log.Fatalf("[postgres_1] org_memberships: prepare CopyIn failed: %v", err)
	}

	count := 0
	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[postgres_1] org_memberships: read row failed: %v", err)
		}
		if len(rec) < 3 {
			log.Fatalf("[postgres_1] org_memberships: invalid row: %#v", rec)
		}

		if _, err := stmt.Exec(rec[0], rec[1], rec[2]); err != nil {
			log.Fatalf("[postgres_1] org_memberships: CopyIn exec failed: %v", err)
		}
		count++
	}

	if _, err := stmt.Exec(); err != nil {
		log.Fatalf("[postgres_1] org_memberships: final CopyIn exec failed: %v", err)
	}
	if err := stmt.Close(); err != nil {
		log.Fatalf("[postgres_1] org_memberships: close stmt failed: %v", err)
	}
	if err := tx.Commit(); err != nil {
		log.Fatalf("[postgres_1] org_memberships: commit failed: %v", err)
	}

	log.Printf("[postgres_1] org_memberships: inserted %d rows in %s",
		count, time.Since(start).Truncate(time.Millisecond))
}

func loadGroupMemberships(db *sql.DB) {
	start := time.Now()
	r, f := openCSV("group_memberships.csv")
	defer f.Close()

	// group_memberships.csv: group_id,user_id,role
	if _, err := r.Read(); err != nil {
		log.Fatalf("[postgres_1] group_memberships: read header failed: %v", err)
	}

	tx, err := db.Begin()
	if err != nil {
		log.Fatalf("[postgres_1] group_memberships: begin tx failed: %v", err)
	}

	stmt, err := tx.Prepare(pq.CopyIn("group_memberships", "group_id", "user_id", "role"))
	if err != nil {
		log.Fatalf("[postgres_1] group_memberships: prepare CopyIn failed: %v", err)
	}

	count := 0
	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[postgres_1] group_memberships: read row failed: %v", err)
		}
		if len(rec) < 3 {
			log.Fatalf("[postgres_1] group_memberships: invalid row: %#v", rec)
		}

		if _, err := stmt.Exec(rec[0], rec[1], rec[2]); err != nil {
			log.Fatalf("[postgres_1] group_memberships: CopyIn exec failed: %v", err)
		}
		count++
	}

	if _, err := stmt.Exec(); err != nil {
		log.Fatalf("[postgres_1] group_memberships: final CopyIn exec failed: %v", err)
	}
	if err := stmt.Close(); err != nil {
		log.Fatalf("[postgres_1] group_memberships: close stmt failed: %v", err)
	}
	if err := tx.Commit(); err != nil {
		log.Fatalf("[postgres_1] group_memberships: commit failed: %v", err)
	}

	log.Printf("[postgres_1] group_memberships: inserted %d rows in %s",
		count, time.Since(start).Truncate(time.Millisecond))
}

func loadResources(db *sql.DB) {
	start := time.Now()
	r, f := openCSV("resources.csv")
	defer f.Close()

	// resources.csv: resource_id,org_id
	if _, err := r.Read(); err != nil {
		log.Fatalf("[postgres_1] resources: read header failed: %v", err)
	}

	tx, err := db.Begin()
	if err != nil {
		log.Fatalf("[postgres_1] resources: begin tx failed: %v", err)
	}

	stmt, err := tx.Prepare(pq.CopyIn("resources", "resource_id", "org_id"))
	if err != nil {
		log.Fatalf("[postgres_1] resources: prepare CopyIn failed: %v", err)
	}

	count := 0
	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[postgres_1] resources: read row failed: %v", err)
		}
		if len(rec) < 2 {
			log.Fatalf("[postgres_1] resources: invalid row: %#v", rec)
		}

		if _, err := stmt.Exec(rec[0], rec[1]); err != nil {
			log.Fatalf("[postgres_1] resources: CopyIn exec failed: %v", err)
		}
		count++
	}

	if _, err := stmt.Exec(); err != nil {
		log.Fatalf("[postgres_1] resources: final CopyIn exec failed: %v", err)
	}
	if err := stmt.Close(); err != nil {
		log.Fatalf("[postgres_1] resources: close stmt failed: %v", err)
	}
	if err := tx.Commit(); err != nil {
		log.Fatalf("[postgres_1] resources: commit failed: %v", err)
	}

	log.Printf("[postgres_1] resources: inserted %d rows in %s",
		count, time.Since(start).Truncate(time.Millisecond))
}

func loadResourceACL(db *sql.DB) {
	start := time.Now()
	r, f := openCSV("resource_acl.csv")
	defer f.Close()

	// resource_acl.csv: resource_id,subject_type,subject_id,relation
	if _, err := r.Read(); err != nil {
		log.Fatalf("[postgres_1] resource_acl: read header failed: %v", err)
	}

	tx, err := db.Begin()
	if err != nil {
		log.Fatalf("[postgres_1] resource_acl: begin tx failed: %v", err)
	}

	stmt, err := tx.Prepare(pq.CopyIn("resource_acl", "resource_id", "subject_type", "subject_id", "relation"))
	if err != nil {
		log.Fatalf("[postgres_1] resource_acl: prepare CopyIn failed: %v", err)
	}

	count := 0
	for {
		rec, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("[postgres_1] resource_acl: read row failed: %v", err)
		}
		if len(rec) < 4 {
			log.Fatalf("[postgres_1] resource_acl: invalid row: %#v", rec)
		}

		if _, err := stmt.Exec(rec[0], rec[1], rec[2], rec[3]); err != nil {
			log.Fatalf("[postgres_1] resource_acl: CopyIn exec failed: %v", err)
		}
		count++
	}

	if _, err := stmt.Exec(); err != nil {
		log.Fatalf("[postgres_1] resource_acl: final CopyIn exec failed: %v", err)
	}
	if err := stmt.Close(); err != nil {
		log.Fatalf("[postgres_1] resource_acl: close stmt failed: %v", err)
	}
	if err := tx.Commit(); err != nil {
		log.Fatalf("[postgres_1] resource_acl: commit failed: %v", err)
	}

	log.Printf("[postgres_1] resource_acl: inserted %d rows in %s",
		count, time.Since(start).Truncate(time.Millisecond))
}
